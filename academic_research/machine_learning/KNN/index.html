<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#9400D3"><meta name="author" content="Joaquin Chou"><meta name="copyright" content="Joaquin Chou"><meta name="generator" content="Hexo 6.3.0"><meta name="theme" content="hexo-theme-yun"><title>k近邻算法 | 喵语小站</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...true?.options,
  });
});</script><link rel="icon" type="image/png" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#9400D3"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"www.joaquinchou.com","root":"/","title":"喵星暖暖窝","version":"1.10.11","mode":"time","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","say":{"api":"https://el-bot-api.vercel.app/api/words/young"},"algolia":{"appID":"L0D85KPS1S","apiKey":"715edff2e91248577c19b580f3efcb3a","indexName":"prod_NAME","hits":{"per_page":8}},"fireworks":{"colors":["0,250,154","255,69,0","33, 78, 194"]},"waline":{"config":{"enable":true,"serverURL":"https://blog-api-joaquinchou.vercel.app","comment":false,"el":"#waline","lang":"zh-CN"},"cdn":"https://fastly.jsdelivr.net/npm/@waline/client@v2/dist/waline.js","dark":"html.dark"},"vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/hexo-theme-yun.js" type="module"></script><script>(function(){
  var bp = document.createElement('script');
  var curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else {
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})();</script><meta name="description" content="关于KNN的问题整理。 KNN简介？k近邻算法(k-nearest neighbor)是一种有监督的分类算法，是通过测量不同特征向量之间的距离来进行分类的。它的思想是如果一个样本在特征空间中最邻近的k个样本大多数属于某个类别，则该样本也属于这个类别。算法过程为  计算测试样本特征向量和其他每个样本的特征向量之间的距离； 对距离进行递增排序，选择距离最小的k个点； 确定这k个点所在类别出现频率； 返">
<meta property="og:type" content="article">
<meta property="og:title" content="k近邻算法">
<meta property="og:url" content="https://www.joaquinchou.com/academic_research/machine_learning/KNN/index.html">
<meta property="og:site_name" content="喵语小站">
<meta property="og:description" content="关于KNN的问题整理。 KNN简介？k近邻算法(k-nearest neighbor)是一种有监督的分类算法，是通过测量不同特征向量之间的距离来进行分类的。它的思想是如果一个样本在特征空间中最邻近的k个样本大多数属于某个类别，则该样本也属于这个类别。算法过程为  计算测试样本特征向量和其他每个样本的特征向量之间的距离； 对距离进行递增排序，选择距离最小的k个点； 确定这k个点所在类别出现频率； 返">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-04-29T16:00:00.000Z">
<meta property="article:modified_time" content="2022-05-16T12:08:39.700Z">
<meta property="article:author" content="Joaquin Chou">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><script defer src="https://fastly.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js" type="module"></script><canvas class="fireworks"></canvas><canvas id="trianglifyContainer"></canvas><script defer src="https://fastly.jsdelivr.net/npm/trianglify@4/dist/trianglify.bundle.js"></script><script>document.addEventListener("DOMContentLoaded", () => {
  const pattern = trianglify({
    width: 800,
    height: 600,
    cellSize: 75,
    palette: ["Oranges", "RdBu", "Purples", "Blues"],
  });
  const canvasOpts = {
    applyCssScaling: false
  }
  document.body.appendChild(pattern.toCanvas(trianglifyContainer, canvasOpts));
});</script><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="Joaquin Chou"><img width="96" loading="lazy" src="https://joaquinchou-1259120139.cos.ap-guangzhou.myqcloud.com/img/img_config/JTpLkT.jpg" alt="Joaquin Chou"></a><div class="site-author-name"><a href="/about/">Joaquin Chou</a></div><a class="site-name" href="/about/site.html">喵语小站</a><sub class="site-subtitle">Hope that someone you love would also love you!</sub><div class="site-description">希望你喜欢的人她/他也爱你！</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:archive-line"></span></span><span class="site-state-item-count">17</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:folder-2-line"></span></span><span class="site-state-item-count">4</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="site-state-item-count">8</span></a></div><a class="site-state-item hty-icon-button" href="/404.html" title="还没想好呢"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:settings-line"></span></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/JoaquinChou" title="GitHub" target="_blank" style="color:#FF00FF"><span class="icon iconify" data-icon="ri:github-line"></span></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/my/m/music/playlist?id=621567138" title="网易云音乐" target="_blank" style="color:#C20C0C"><span class="icon iconify" data-icon="ri:netease-cloud-music-line"></span></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><span class="icon iconify" data-icon="ri:genderless-line"></span></a><a class="links-item hty-icon-button" href="/albums/" title="我的相册" style="color:#DA70D6"><span class="icon iconify" data-icon="ri:gallery-line"></span></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><span class="icon iconify" data-icon="ri:contrast-2-line"></span></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN%E7%AE%80%E4%BB%8B%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">KNN简介？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN%E6%95%B0%E6%8D%AE%E9%9C%80%E8%A6%81%E5%BD%92%E4%B8%80%E5%8C%96%E4%B9%88%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">KNN数据需要归一化么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">KNN优缺点？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN%E7%9A%84k%E5%80%BC%E6%80%8E%E4%B9%88%E9%80%89%EF%BC%9F"><span class="toc-number">4.</span> <span class="toc-text">KNN的k值怎么选？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN%E4%B8%ADk%E5%80%BC%E7%9A%84%E8%AE%BE%E7%BD%AE%E5%AF%B9%E6%A8%A1%E5%9E%8B%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D%EF%BC%9F"><span class="toc-number">5.</span> <span class="toc-text">KNN中k值的设置对模型有什么影响？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN%E4%B8%89%E8%A6%81%E7%B4%A0%EF%BC%9F"><span class="toc-number">6.</span> <span class="toc-text">KNN三要素？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8K-means%E6%88%96KNN%E4%B8%AD%EF%BC%8C%E7%94%A8%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB%E5%92%8C%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">7.</span> <span class="toc-text">在K-means或KNN中，用欧氏距离和曼哈顿距离度量有什么区别？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kd%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84%EF%BC%9Fkd%E6%A0%91%E7%9A%84%E6%9E%84%E5%BB%BA%EF%BC%9FKNN%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8kd%E6%A0%91%EF%BC%9F"><span class="toc-number">8.</span> <span class="toc-text">kd树的结构？kd树的构建？KNN如何使用kd树？</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#9400D3;"><link itemprop="mainEntityOfPage" href="https://www.joaquinchou.com/academic_research/machine_learning/KNN/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Joaquin Chou"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="喵语小站"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">k近邻算法</h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="创建时间：2022-04-30 00:00:00" itemprop="dateCreated datePublished" datetime="2022-04-30T00:00:00+08:00">2022-04-30</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><span class="icon iconify" data-icon="ri:file-word-line"></span></span> <span title="本文字数">1.5k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><span class="icon iconify" data-icon="ri:timer-line"></span></span> <span title="阅读时长">5m</span></span></span><span class="post-busuanzi"><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读次数"><span class="icon iconify" data-icon="ri:eye-line"></span> <span id="busuanzi_value_page_pv"></span></span></span><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><span class="icon iconify" data-icon="ri:folder-line"></span></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E5%96%B5%E8%AF%AD%E7%AC%94%E8%AE%B0/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">喵语笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="--text-color:#3776ab"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="tag-name">机器学习</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><p>关于KNN的<a target="_blank" rel="noopener" href="https://www.nowcoder.com/discuss/681294">问题</a>整理。</p>
<h2 id="KNN简介？"><a href="#KNN简介？" class="headerlink" title="KNN简介？"></a>KNN简介？</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhangkkit/article/details/106173651">k近邻算法</a>(k-nearest neighbor)是一种有监督的分类算法，是通过测量不同特征向量之间的距离来进行分类的。它的思想是<b>如果一个样本在特征空间中最邻近的k个样本大多数属于某个类别，则该样本也属于这个类别。</b>算法过程为</p>
<ul>
<li>计算测试样本特征向量和其他每个样本的特征向量之间的距离；</li>
<li>对距离进行递增排序，选择距离最小的k个点；</li>
<li>确定这k个点所在类别出现频率；</li>
<li>返回这k个点出现频率最高的类别作为当前测试样本的预测类别。</li>
</ul>
<span id="more"></span>

<h2 id="KNN数据需要归一化么？"><a href="#KNN数据需要归一化么？" class="headerlink" title="KNN数据需要归一化么？"></a>KNN数据需要归一化么？</h2><p>数据是否归一化取决于模型是关注<b>变量的取值还是变量之间的分布</b>。KNN中有计算两个特征向量的距离操作，因此<font color='red'>需要进行数据归一化，来削弱不同特征之间数量级的差异性</font>。</p>
<h2 id="KNN优缺点？"><a href="#KNN优缺点？" class="headerlink" title="KNN优缺点？"></a>KNN优缺点？</h2><ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhangkkit/article/details/106173651">优点</a>：<ul>
<li>思想简单，既可以做分类，也可以做回归；</li>
<li>可用于非线性的分类；</li>
<li>适用于样本容量比较大的类域进行分类。</li>
</ul>
</li>
<li>缺点：<ul>
<li>当特征空间中样本数量和样本特征维度比较大时，计算量大，分类速度慢；</li>
<li>k值难以确定，一般多次交叉验证实验调整k值；</li>
<li>对不均衡的样本集敏感，当少数类的样本进行测试时，由于k近邻的样本属于多数类而导致分类错误。  </li>
</ul>
</li>
</ul>
<h2 id="KNN的k值怎么选？"><a href="#KNN的k值怎么选？" class="headerlink" title="KNN的k值怎么选？"></a>KNN的k值怎么选？</h2><p>一般通过多次实验以交叉验证的方式给k值打分，寻找分数最高的k值。</p>
<h2 id="KNN中k值的设置对模型有什么影响？"><a href="#KNN中k值的设置对模型有什么影响？" class="headerlink" title="KNN中k值的设置对模型有什么影响？"></a>KNN中k值的设置对模型有什么影响？</h2><ul>
<li>如果k值设置过小，会导致结果对近邻的样本点非常敏感，此时如果有噪声(样本打错标签)的影响，会导致预测错误，过小的k值会使得模型变复杂，容易过拟合到噪声；</li>
<li>如果k值设置过大，会导致某些其他类别的样本点也贡献了作用，会导致预测错误，过大的k值会使得模型变简单，容易欠拟合，模式倾向于输出类别数多的类；</li>
<li>如果k值设置等于样本数，此时无论测试输入是什么，模型只会输出类别数最多的类。</li>
</ul>
<h2 id="KNN三要素？"><a href="#KNN三要素？" class="headerlink" title="KNN三要素？"></a>KNN三要素？</h2><ul>
<li>距离度量：可以使用欧氏距离或者曼哈顿距离($L_p$距离的特例)进行度量；</li>
<li>k值的选择：一般通过多次交叉验证选择最优的k值；</li>
<li>分类决策规则：常用的是多数表决的规则。</li>
</ul>
<h2 id="在K-means或KNN中，用欧氏距离和曼哈顿距离度量有什么区别？"><a href="#在K-means或KNN中，用欧氏距离和曼哈顿距离度量有什么区别？" class="headerlink" title="在K-means或KNN中，用欧氏距离和曼哈顿距离度量有什么区别？"></a>在K-means或KNN中，用欧氏距离和曼哈顿距离度量有什么区别？</h2><p>曼哈顿距离和欧式距离的用途不一样。<br>对于$(x_1, y_1), (x_2, y_2)$，</p>
<p>欧式距离定义为<br>$$d(x,y):=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}$$</p>
<p>曼哈顿距离定义为<br>$$d(x,y):=|x_1-y_1|+|x_2-y_2|$$</p>
<p>曼哈顿距离是在直接坐标系中两点所形成的线段对坐标轴的投影。曼哈顿距离只能计算水平或垂直的距离，有维度限制。而欧式距离可用于任何空间距离的计算。一般来说，数据点会存在于任何空间中，用欧氏距离更好点。</p>
<h2 id="kd树的结构？kd树的构建？KNN如何使用kd树？"><a href="#kd树的结构？kd树的构建？KNN如何使用kd树？" class="headerlink" title="kd树的结构？kd树的构建？KNN如何使用kd树？"></a>kd树的结构？kd树的构建？KNN如何使用kd树？</h2><p>关于kd树的<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/23966698">详解</a>。</p>
<ul>
<li><p>kd树的结构是一个<b>二叉树</b>的结构，它的每一个节点<b>记录【特征坐标，切分轴，指向左孩子的指针，指向右孩子的指针】</b>，特征坐标是在线性空间$\R^n$中的一个点$(x_1,x_2,…,x_n)$，切分轴是指沿着第$r$轴$(1≤r≤n)$的一次切分，左右孩子仍是kd树，并且左孩子的特征点在特征空间上在根节点的左边，右孩子的特征点在根节点的右边。</p>
</li>
<li><p>kd树的构建，给定数据集$S\subseteq \R^n$和切分轴$r$，使用递归算法构建一个基于数据集的二叉树；</p>
<ul>
<li>如果集合$S$中的元素个数大于1，那么将所有点按第$r$个坐标进行排序，然后选出中位元素作为当前点的特征坐标(即切分为止)，并记录切分轴$r$；</li>
<li>再对中位元素之前的子集合$S_L$和之后的子集合$S_R$，更新$r$轴($r \leftarrow(r+1)\mod n$)，以第$r$轴为切分轴递归创建kd子树；</li>
<li>如果集合$S$中的元素个数等于1，那么当前特征点就是该处节点的特征数据。</li>
</ul>
</li>
<li><p>kd树的使用。任务是寻找距离测试点$p$最近的$k$个样本，记录在长度为$k$的列表$L$中。</p>
<ul>
<li>从根节点出发，根据$p$在第$r$轴的坐标值与当前特征节点的相应坐标值的大小比较，小于则会往左枝向下遍历，否则往右枝向下遍历；</li>
<li>到达叶节点后，如果$L$不满，把当前叶节点的特征坐标加入$L$，如果满了，计算当前叶节点和$p$的欧氏距离，同时找到$L$中的距离$p$最长的节点，如果当前距离小于最长距离，则当前节点替换最长距离节点，同时标记为已访问。</li>
<li>从叶节点向上回溯访问未访问过的节点，如果$L$不满，把当前节点的特征坐标加入$L$，如果满了，计算距离看是否进行节点的替换。<font color='grey'>(可通过计算$p$和切分面的距离看是否需要剪掉右子树，提升遍历效率)</font></li>
</ul>
</li>
</ul>
</div></section><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><span class="icon iconify" data-icon="ri:hand-coin-line"></span></span><div id="reward-comment">来都来了，不点一下麽？(●ˇ∀ˇ●)</div><div id="qr" style="display:none;"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://joaquinchou-1259120139.cos.ap-guangzhou.myqcloud.com/img/img_config/alipay.jpg"><img loading="lazy" src="https://joaquinchou-1259120139.cos.ap-guangzhou.myqcloud.com/img/img_config/alipay.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><span class="icon iconify" data-icon="ri:alipay-line"></span></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://joaquinchou-1259120139.cos.ap-guangzhou.myqcloud.com/img/img_config/QQ.png"><img loading="lazy" src="https://joaquinchou-1259120139.cos.ap-guangzhou.myqcloud.com/img/img_config/QQ.png" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><span class="icon iconify" data-icon="ri:qq-line"></span></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://joaquinchou-1259120139.cos.ap-guangzhou.myqcloud.com/img/img_config/wechat.png"><img loading="lazy" src="https://joaquinchou-1259120139.cos.ap-guangzhou.myqcloud.com/img/img_config/wechat.png" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><span class="icon iconify" data-icon="ri:wechat-pay-line"></span></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Joaquin Chou</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://www.joaquinchou.com/academic_research/machine_learning/KNN/" title="k近邻算法">https://www.joaquinchou.com/academic_research/machine_learning/KNN/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><span class="icon iconify" data-icon="ri:creative-commons-line"></span><span class="icon iconify" data-icon="ri:creative-commons-by-line"></span><span class="icon iconify" data-icon="ri:creative-commons-nc-line"></span><span class="icon iconify" data-icon="ri:creative-commons-sa-line"></span></a> 许可协议。</li></ul><script>document.addEventListener('copy', function (event) {
  const clipboardData = event.clipboardData || window.clipboardData;
  if (!clipboardData) { return; }
  const text = window.getSelection().toString();
  if (text) {
    event.preventDefault();
    clipboardData.setData('text/plain', text + '\n\n本文作者：Joaquin Chou\n本文链接：https://www.joaquinchou.com/academic_research/machine_learning/KNN/\n版权声明：本博客所有文章除特别声明外，均默认采用 CC BY-NC-SA 4.0 许可协议。');
  }
});</script></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/academic_research/machine_learning/SVM/" rel="prev" title="SVM"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">SVM</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/academic_research/machine_learning/Linear_and_Logistic_Regression/" rel="next" title="线性回归和逻辑回归"><span class="post-nav-text">线性回归和逻辑回归</span><span class="icon iconify" data-icon="ri:arrow-right-s-line"></span></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>可以点击下方进行评论哟！</span><br></div><div id="waline"></div><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@waline/client@v2/dist/waline.css"><script>window.CONFIG.waline.config.path = "/academic_research/machine_learning/KNN/"</script><div class="js-Pjax"><script src="/js/comments/waline.js" type="module" defer></script></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2023 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> Joaquin Chou</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v6.3.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.11</span></div><div class="live-time"><span>本博客已萌萌哒地运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  setTimeout(blog_live_time, 1000);
  const start = new Date('2020-11-12T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = ` ${passDay} 天 ${passHour} 小时 ${passMinute} 分 ${passSecond} 秒`;
}
blog_live_time();
</script></div><div id="busuanzi"><span id="busuanzi_container_site_uv" title="总访客量"><span><span class="icon iconify" data-icon="ri:user-line"></span></span><span id="busuanzi_value_site_uv"></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv" title="总访问量"><span><span class="icon iconify" data-icon="ri:eye-line"></span></span><span id="busuanzi_value_site_pv"></span></span><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#9400D3" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="搜索"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:search-line"></span></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script defer src="https://fastly.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script defer src="https://fastly.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script defer src="/js/search/algolia-search.js" type="module"></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><span class="icon iconify" data-icon="ri:close-line"></span></span></div><div class="search-input-container"></div><div class="algolia-results"><div id="algolia-stats"></div><div id="algolia-hits"></div><div class="algolia-pagination" id="algolia-pagination"></div></div></div><script>function initMourn() {
  const date = new Date();
  const today = (date.getMonth() + 1) + "-" + date.getDate()
  const mourn_days = ["4-4","9-18","3-3"]
  if (mourn_days.includes(today)) {
    document.documentElement.style.filter = "grayscale(1)";
  }
}
initMourn();</script></body></html>